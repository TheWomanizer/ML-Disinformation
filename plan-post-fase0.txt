# PLAN POST-FASE 0: AN√ÅLISIS INTEGRAL Y ROADMAP DETALLADO PARA FASE 1
# Sistema Integral Multi-Capa para la Detecci√≥n de Desinformaci√≥n
# Versi√≥n: 2.1 - Post An√°lisis Cr√≠tico Fase 0
# Fecha: 2025-08-14
# Estado: Transici√≥n Fase 0 ‚Üí Fase 1

================================================================================
# üìã RESUMEN EJECUTIVO - ESTADO ACTUAL POST-FASE 0
================================================================================

## ‚úÖ LOGROS COMPLETADOS EN FASE 0:
- Dataset principal procesado: 134,198 filas √ó 58 columnas (reducci√≥n de 6 columnas)
- Datos de texto separados correctamente para an√°lisis NLP
- Variables problem√°ticas eliminadas: 'Unnamed: 0', 'embeddings', 'following'
- Data leakage prevenci√≥n: 'majority_target' removido
- Balance de clases verificado: 1.06:1 (pr√°cticamente balanceado)
- M√©trica recomendada: accuracy (debido al buen balance)
- 48 outliers extremos detectados en m√∫ltiples variables
- RobustScaler aplicado (aunque con limitaciones por outliers brutales)

## üö® DESAF√çOS IDENTIFICADOS:
- Outliers extremos persistentes (valores hasta 460,320 post-escalado)
- Datos originales con rangos brutales (m√°x: 130,601,913)
- RobustScaler insuficiente para manejar estos extremos
- Necesidad de estrategias avanzadas de manejo de outliers

## üìä RECURSOS DISPONIBLES:
- dataset_features_processed.csv (58 columnas num√©ricas escaladas)
- text_data_for_nlp.csv (statement + tweet para BERT)
- robust_scaler.pkl (scaler entrenado, aunque con limitaciones)
- processing_metadata.json (metadatos completos del procesamiento)

================================================================================
# üéØ INTERPRETACI√ìN DEL PLAN PRINCIPAL - REALINEACI√ìN ESTRAT√âGICA
================================================================================

## FILOSOF√çA ORIGINAL VS REALIDAD ACTUAL:

### PLAN ORIGINAL (3 Preguntas Clave):
1. ¬øQU√â? ‚Üí ¬øEs esta noticia falsa o verdadera? (Clasificaci√≥n de Contenido)
2. ¬øQUI√âN? ‚Üí ¬øLa fuente que publica la noticia es cre√≠ble? ¬øEs un bot? (An√°lisis de Fuente)
3. ¬øPOR QU√â? ‚Üí ¬øQu√© factores llevaron al sistema a su conclusi√≥n? (Explicabilidad)

### ADAPTACI√ìN POST-FASE 0:
‚úÖ PREGUNTA 1 (¬øQU√â?) - PERFECTAMENTE ALINEADA:
- Tenemos BinaryNumTarget balanceado (1.06:1)
- Features tradicionales de ML disponibles (58 variables)
- Datos de texto para BERT/NLP preparados
- Estrategia: Modelo h√≠brido XGBoost + BERT como planeado

‚ö†Ô∏è PREGUNTA 2 (¬øQUI√âN?) - REQUIERE ADAPTACI√ìN:
- Variables de credibilidad disponibles: 'cred', 'BotScore', 'BotScoreBinary'
- Variables de influencia: 'normalize_influence', 'followers_count', etc.
- DESAF√çO: Outliers extremos en variables de usuario (followers: 86K escalado)
- Estrategia: Implementar Winsorizing antes de an√°lisis de credibilidad

‚úÖ PREGUNTA 3 (¬øPOR QU√â?) - T√âCNICAMENTE FACTIBLE:
- SHAP y LIME aplicables a modelos finales
- 58 features num√©ricas permiten an√°lisis granular
- Datos de texto permiten explicabilidad a nivel de palabras/frases

================================================================================
# üöÄ FASE 1 DETALLADA - D√çA 2 COMPLETO: MODELOS BASE
================================================================================

## TIEMPO ESTIMADO: 8-10 horas
## OBJETIVO: Crear modelos base robustos para clasificaci√≥n de contenido

### ‚è∞ CRONOGRAMA DETALLADO D√çA 2:

üìÖ **MA√ëANA (4-5 horas):**
- 09:00-10:30 ‚Üí Configuraci√≥n, EDA post-limpieza, manejo de outliers
- 10:30-12:00 ‚Üí Modelo XGBoost con features tradicionales
- 12:00-13:00 ‚Üí Evaluaci√≥n y optimizaci√≥n XGBoost

üìÖ **TARDE (4-5 horas):**
- 14:00-15:30 ‚Üí Preparaci√≥n datos texto y modelo BERT
- 15:30-17:00 ‚Üí Entrenamiento y fine-tuning BERT
- 17:00-18:00 ‚Üí Evaluaci√≥n comparativa y documentaci√≥n

### üìã ACTIVIDAD 1.1: CONFIGURACI√ìN Y AN√ÅLISIS POST-LIMPIEZA (90 min)

#### üîß Subtarea 1.1.1: Configuraci√≥n del Entorno (15 min)
```python
# Notebook: 03_fase1_modelos_base.ipynb
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import xgboost as xgb
from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer
import torch
import warnings
warnings.filterwarnings('ignore')
```

#### üîç Subtarea 1.1.2: Carga y Verificaci√≥n de Datos Procesados (20 min)
```python
# Cargar datos procesados
df_features = pd.read_csv('../processed_data/dataset_features_processed.csv')
df_text = pd.read_csv('../processed_data/text_data_for_nlp.csv')
scaler = joblib.load('../processed_data/robust_scaler.pkl')

# Verificaci√≥n de integridad
print(f"Features shape: {df_features.shape}")
print(f"Text data shape: {df_text.shape}")
print(f"Balance verificado: {df_features['BinaryNumTarget'].value_counts(normalize=True)}")

# Identificar variables con outliers extremos persistentes
outlier_threshold = 50
extreme_cols = []
for col in df_features.select_dtypes(include=[np.number]).columns:
    if col != 'BinaryNumTarget':
        max_abs = df_features[col].abs().max()
        if max_abs > outlier_threshold:
            extreme_cols.append((col, max_abs))

print(f"Columnas con outliers extremos: {len(extreme_cols)}")
```

#### üõ†Ô∏è Subtarea 1.1.3: Estrategia de Manejo de Outliers Extremos (55 min)

**CR√çTICO: Esta es la correcci√≥n m√°s importante post-Fase 0**

```python
from scipy.stats import mstats

# Estrategia 1: Winsorizing para variables extremas
print("Aplicando Winsorizing a variables extremas...")
df_features_clean = df_features.copy()

# Identificar top 10 variables m√°s problem√°ticas
extreme_cols_sorted = sorted(extreme_cols, key=lambda x: x[1], reverse=True)[:10]
winsorize_cols = [col for col, _ in extreme_cols_sorted]

# Aplicar Winsorizing (limitar a percentiles 1% y 99%)
for col in winsorize_cols:
    original_max = df_features_clean[col].abs().max()
    df_features_clean[col] = mstats.winsorize(df_features_clean[col], limits=[0.01, 0.01])
    new_max = df_features_clean[col].abs().max()
    print(f"{col}: {original_max:.1f} ‚Üí {new_max:.1f}")

# Re-escalar las variables winorizadas
from sklearn.preprocessing import RobustScaler
winsor_scaler = RobustScaler()
df_features_clean[winsorize_cols] = winsor_scaler.fit_transform(df_features_clean[winsorize_cols])

# Verificaci√≥n final
final_max = df_features_clean.select_dtypes(include=[np.number]).drop('BinaryNumTarget', axis=1).abs().max().max()
print(f"Valor m√°ximo absoluto final: {final_max:.3f}")

# Guardar datos corregidos para modelado
df_features_clean.to_csv('../processed_data/dataset_features_final.csv', index=False)
joblib.dump(winsor_scaler, '../processed_data/winsor_scaler.pkl')
```

### üìã ACTIVIDAD 1.2: MODELO XGBOOST CON FEATURES TRADICIONALES (90 min)

#### üèóÔ∏è Subtarea 1.2.1: Preparaci√≥n de Datos para XGBoost (20 min)
```python
# Separar features y target
X = df_features_clean.drop('BinaryNumTarget', axis=1)
y = df_features_clean['BinaryNumTarget']

# Train-test split estratificado (aunque el balance es bueno)
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Train shape: {X_train.shape}")
print(f"Test shape: {X_test.shape}")
print(f"Train balance: {y_train.value_counts(normalize=True)}")
```

#### üöÄ Subtarea 1.2.2: Entrenamiento XGBoost Base (30 min)
```python
# Configuraci√≥n XGBoost optimizada para este dataset
xgb_params = {
    'objective': 'binary:logistic',
    'eval_metric': 'logloss',
    'max_depth': 6,
    'learning_rate': 0.1,
    'n_estimators': 100,
    'subsample': 0.8,
    'colsample_bytree': 0.8,
    'random_state': 42,
    'n_jobs': -1
}

# Entrenar modelo base
xgb_model = xgb.XGBClassifier(**xgb_params)
xgb_model.fit(X_train, y_train)

# Predicciones base
y_pred_xgb = xgb_model.predict(X_test)
y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]

print("XGBoost entrenado exitosamente")
```

#### üìä Subtarea 1.2.3: Evaluaci√≥n XGBoost (25 min)
```python
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score

# M√©tricas principales
accuracy_xgb = accuracy_score(y_test, y_pred_xgb)
f1_xgb = f1_score(y_test, y_pred_xgb)
precision_xgb = precision_score(y_test, y_pred_xgb)
recall_xgb = recall_score(y_test, y_pred_xgb)
auc_xgb = roc_auc_score(y_test, y_pred_proba_xgb)

print("RESULTADOS XGBOOST:")
print(f"Accuracy: {accuracy_xgb:.4f}")
print(f"F1-Score: {f1_xgb:.4f}")
print(f"Precision: {precision_xgb:.4f}")
print(f"Recall: {recall_xgb:.4f}")
print(f"AUC-ROC: {auc_xgb:.4f}")

# Matriz de confusi√≥n
cm_xgb = confusion_matrix(y_test, y_pred_xgb)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues')
plt.title('Matriz de Confusi√≥n - XGBoost')
plt.ylabel('Real')
plt.xlabel('Predicci√≥n')
plt.show()
```

#### üîß Subtarea 1.2.4: Optimizaci√≥n Hyperpar√°metros (15 min)
```python
from sklearn.model_selection import RandomizedSearchCV

# Grid de hiperpar√°metros para optimizaci√≥n r√°pida
param_dist = {
    'max_depth': [4, 6, 8],
    'learning_rate': [0.05, 0.1, 0.2],
    'n_estimators': [100, 200, 300],
    'subsample': [0.8, 0.9, 1.0]
}

# B√∫squeda randomizada (m√°s r√°pida que Grid Search)
random_search = RandomizedSearchCV(
    xgb.XGBClassifier(random_state=42),
    param_distributions=param_dist,
    n_iter=20,
    cv=3,
    scoring='f1',
    n_jobs=-1,
    random_state=42
)

random_search.fit(X_train, y_train)
best_xgb = random_search.best_estimator_

print(f"Mejores par√°metros: {random_search.best_params_}")
print(f"Mejor F1-Score CV: {random_search.best_score_:.4f}")
```

### üìã ACTIVIDAD 1.3: MODELO BERT PARA AN√ÅLISIS DE TEXTO (90 min)

#### üî§ Subtarea 1.3.1: Preparaci√≥n de Datos de Texto (25 min)
```python
# Combinar statement y tweet en un solo texto
df_text['combined_text'] = df_text['statement'].fillna('') + " " + df_text['tweet'].fillna('')
df_text['target'] = df_features_clean['BinaryNumTarget']

# Limpieza b√°sica de texto
import re
def clean_text(text):
    # Remover URLs
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)
    # Remover menciones y hashtags excesivos
    text = re.sub(r'@\w+', '', text)
    text = re.sub(r'#(\w+)', r'\1', text)
    # Limpiar espacios m√∫ltiples
    text = re.sub(r'\s+', ' ', text).strip()
    return text

df_text['text_clean'] = df_text['combined_text'].apply(clean_text)

# Split train-test para texto
X_text_train, X_text_test, y_text_train, y_text_test = train_test_split(
    df_text['text_clean'], df_text['target'], 
    test_size=0.2, random_state=42, stratify=df_text['target']
)

print(f"Textos de entrenamiento: {len(X_text_train)}")
print(f"Textos de prueba: {len(X_text_test)}")
```

#### ü§ñ Subtarea 1.3.2: Configuraci√≥n BERT en Espa√±ol (30 min)
```python
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from transformers import TrainingArguments, Trainer
import torch

# Modelo BERT multiling√ºe optimizado para espa√±ol
model_name = "dccuchile/bert-base-spanish-wwm-uncased"

# Cargar tokenizer y modelo
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name, 
    num_labels=2,
    problem_type="single_label_classification"
)

# Tokenizaci√≥n
def tokenize_function(texts):
    return tokenizer(
        texts.tolist(),
        padding=True,
        truncation=True,
        max_length=512,
        return_tensors="pt"
    )

# Tokenizar datos
train_encodings = tokenize_function(X_text_train)
test_encodings = tokenize_function(X_text_test)

# Crear datasets para PyTorch
class NewsDataset(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels.values

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = NewsDataset(train_encodings, y_text_train)
test_dataset = NewsDataset(test_encodings, y_text_test)
```

#### üéØ Subtarea 1.3.3: Fine-tuning BERT (25 min)
```python
# Configuraci√≥n de entrenamiento
training_args = TrainingArguments(
    output_dir='../models/bert_news_classifier',
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    warmup_steps=500,
    weight_decay=0.01,
    logging_dir='../logs',
    logging_steps=100,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    metric_for_best_model="eval_loss",
    greater_is_better=False
)

# Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    tokenizer=tokenizer
)

# Entrenamiento
print("Iniciando fine-tuning de BERT...")
trainer.train()

# Guardar modelo
trainer.save_model('../models/bert_final')
tokenizer.save_pretrained('../models/bert_final')
```

#### üìä Subtarea 1.3.4: Evaluaci√≥n BERT (10 min)
```python
# Predicciones BERT
predictions = trainer.predict(test_dataset)
y_pred_bert = np.argmax(predictions.predictions, axis=1)
y_pred_proba_bert = torch.softmax(torch.tensor(predictions.predictions), dim=1)[:, 1]

# M√©tricas BERT
accuracy_bert = accuracy_score(y_text_test, y_pred_bert)
f1_bert = f1_score(y_text_test, y_pred_bert)
precision_bert = precision_score(y_text_test, y_pred_bert)
recall_bert = recall_score(y_text_test, y_pred_bert)
auc_bert = roc_auc_score(y_text_test, y_pred_proba_bert)

print("RESULTADOS BERT:")
print(f"Accuracy: {accuracy_bert:.4f}")
print(f"F1-Score: {f1_bert:.4f}")
print(f"Precision: {precision_bert:.4f}")
print(f"Recall: {recall_bert:.4f}")
print(f"AUC-ROC: {auc_bert:.4f}")
```

### üìã ACTIVIDAD 1.4: EVALUACI√ìN COMPARATIVA Y AN√ÅLISIS (60 min)

#### üìä Subtarea 1.4.1: Comparaci√≥n Directa de Modelos (20 min)
```python
# Crear DataFrame comparativo
comparison_results = pd.DataFrame({
    'Modelo': ['XGBoost', 'BERT'],
    'Accuracy': [accuracy_xgb, accuracy_bert],
    'F1-Score': [f1_xgb, f1_bert],
    'Precision': [precision_xgb, precision_bert],
    'Recall': [recall_xgb, recall_bert],
    'AUC-ROC': [auc_xgb, auc_bert]
})

print("COMPARACI√ìN DE MODELOS BASE:")
display(comparison_results.round(4))

# Visualizaci√≥n comparativa
metrics = ['Accuracy', 'F1-Score', 'Precision', 'Recall', 'AUC-ROC']
x = np.arange(len(metrics))
width = 0.35

fig, ax = plt.subplots(figsize=(12, 6))
bars1 = ax.bar(x - width/2, [accuracy_xgb, f1_xgb, precision_xgb, recall_xgb, auc_xgb], 
               width, label='XGBoost', alpha=0.8)
bars2 = ax.bar(x + width/2, [accuracy_bert, f1_bert, precision_bert, recall_bert, auc_bert], 
               width, label='BERT', alpha=0.8)

ax.set_xlabel('M√©tricas')
ax.set_ylabel('Score')
ax.set_title('Comparaci√≥n de Rendimiento: XGBoost vs BERT')
ax.set_xticks(x)
ax.set_xticklabels(metrics)
ax.legend()
ax.set_ylim(0, 1)

plt.tight_layout()
plt.show()
```

#### üîç Subtarea 1.4.2: An√°lisis de Fortalezas y Debilidades (25 min)
```python
# An√°lisis de errores - casos donde cada modelo falla
# Encontrar muestras donde XGBoost acierta y BERT falla
xgb_correct = (y_pred_xgb == y_test)
bert_correct = (y_pred_bert == y_text_test)

# Casos interesantes para an√°lisis
xgb_wins = np.where(xgb_correct & ~bert_correct)[0]
bert_wins = np.where(~xgb_correct & bert_correct)[0]
both_fail = np.where(~xgb_correct & ~bert_correct)[0]

print(f"Casos donde XGBoost acierta y BERT falla: {len(xgb_wins)}")
print(f"Casos donde BERT acierta y XGBoost falla: {len(bert_wins)}")
print(f"Casos donde ambos fallan: {len(both_fail)}")

# An√°lisis de importancia de features en XGBoost
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': best_xgb.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 10 features m√°s importantes (XGBoost):")
display(feature_importance.head(10))

# Visualizaci√≥n de importancia
plt.figure(figsize=(10, 8))
sns.barplot(data=feature_importance.head(15), x='importance', y='feature')
plt.title('Top 15 Features M√°s Importantes - XGBoost')
plt.xlabel('Importancia')
plt.tight_layout()
plt.show()
```

#### üìÑ Subtarea 1.4.3: Documentaci√≥n y Preparaci√≥n para Fase 2 (15 min)
```python
# Guardar resultados y modelos
results_summary = {
    'fecha_entrenamiento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),
    'modelos_entrenados': ['XGBoost', 'BERT'],
    'xgboost_metrics': {
        'accuracy': float(accuracy_xgb),
        'f1_score': float(f1_xgb),
        'precision': float(precision_xgb),
        'recall': float(recall_xgb),
        'auc_roc': float(auc_xgb)
    },
    'bert_metrics': {
        'accuracy': float(accuracy_bert),
        'f1_score': float(f1_bert),
        'precision': float(precision_bert),
        'recall': float(recall_bert),
        'auc_roc': float(auc_bert)
    },
    'mejor_modelo': 'XGBoost' if f1_xgb > f1_bert else 'BERT',
    'outliers_corregidos': len(extreme_cols),
    'features_finales': int(X.shape[1]),
    'datos_entrenamiento': int(len(X_train)),
    'preparado_para_fase2': True
}

# Guardar metadatos de Fase 1
with open('../processed_data/fase1_results.json', 'w') as f:
    json.dump(results_summary, f, indent=2)

# Guardar modelos entrenados
joblib.dump(best_xgb, '../models/xgboost_final.pkl')

print("‚úÖ FASE 1 COMPLETADA EXITOSAMENTE")
print("üìÅ Archivos generados:")
print("  ‚Ä¢ ../models/xgboost_final.pkl")
print("  ‚Ä¢ ../models/bert_final/ (directorio)")
print("  ‚Ä¢ ../processed_data/fase1_results.json")
print("  ‚Ä¢ ../processed_data/dataset_features_final.csv")
```

================================================================================
# üîÆ PREPARACI√ìN PARA FASE 2: AN√ÅLISIS DE FUENTES Y CREDIBILIDAD
================================================================================

## OBJETIVOS FASE 2 (D√çA 3):
1. **Puntuaci√≥n de Credibilidad** usando Target Encoding con variables de usuario
2. **Detector de Bots** mejorado combinando BotScore con features de comportamiento
3. **Integraci√≥n** de credibilidad con modelos base de Fase 1
4. **Manejo avanzado** de outliers en variables de usuario (followers, etc.)

## PREPARATIVOS NECESARIOS:
- An√°lisis profundo de variables de credibilidad disponibles
- Estrategia de Target Encoding para 'cred' y variables relacionadas
- Desarrollo de score combinado de credibilidad
- Pipeline de integraci√≥n con modelos XGBoost y BERT

## ARCHIVOS REQUERIDOS PARA FASE 2:
‚úÖ dataset_features_final.csv (con outliers corregidos)
‚úÖ xgboost_final.pkl (modelo base entrenado)
‚úÖ bert_final/ (modelo BERT fine-tuneado)
‚úÖ fase1_results.json (m√©tricas de referencia)

================================================================================
# üìä M√âTRICAS DE √âXITO ESPERADAS FASE 1
================================================================================

## OBJETIVOS M√çNIMOS:
- XGBoost F1-Score: ‚â• 0.85
- BERT F1-Score: ‚â• 0.80
- Diferencia m√°xima entre modelos: ‚â§ 0.10
- AUC-ROC ambos modelos: ‚â• 0.90

## OBJETIVOS OPTIMISTAS:
- XGBoost F1-Score: ‚â• 0.90
- BERT F1-Score: ‚â• 0.87
- AUC-ROC ambos modelos: ‚â• 0.95
- Identificaci√≥n clara de fortalezas complementarias

## CRITERIOS DE √âXITO:
‚úÖ Modelos base funcionando correctamente
‚úÖ Outliers bajo control (max_abs < 50 post-winsorizing)
‚úÖ Pipeline reproducible y documentado
‚úÖ An√°lisis de errores completo
‚úÖ Preparaci√≥n s√≥lida para Fase 2

================================================================================
# üöÄ CONCLUSIONES Y SIGUIENTE ACCI√ìN
================================================================================

La Fase 0 ha sido completada con √©xito parcial. Los principales desaf√≠os de outliers extremos han sido identificados y se han propuesto soluciones robustas (Winsorizing + re-escalado). 

La Fase 1 est√° completamente dise√±ada y lista para ejecuci√≥n. El enfoque dual XGBoost + BERT aprovecha tanto las features tradicionales como el an√°lisis de texto, manteniendo fidelidad al plan original del proyecto.

**ACCI√ìN INMEDIATA**: Ejecutar Fase 1 seg√∫n este plan detallado, con especial atenci√≥n al manejo de outliers en las primeras etapas.

**RIESGO PRINCIPAL**: Los outliers extremos podr√≠an afectar el rendimiento de XGBoost si no se manejan adecuadamente con Winsorizing.

**OPORTUNIDAD PRINCIPAL**: La combinaci√≥n de modelos podr√≠a generar un sistema h√≠brido superior a cada modelo individual.

ESTADO: ‚úÖ LISTO PARA FASE 1 - EJECUTAR INMEDIATAMENTE